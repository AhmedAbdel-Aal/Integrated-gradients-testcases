{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5901dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01ce7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bde0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define the 2-layer neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        super().__init__()\n",
    "        set_seed(0)\n",
    "        self.num_in = num_in\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_out = num_out\n",
    "        self.lin1 = nn.Linear(num_in, num_hidden)\n",
    "        self.lin2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lin3 = nn.Linear(num_hidden, num_out)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        lin1 = F.relu(self.lin1(input))\n",
    "        lin2 = F.relu(self.lin2(lin1))\n",
    "        lin3 = self.lin3(lin2)\n",
    "        return self.softmax(lin3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45af781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input and baseline\n",
    "num_in = 50\n",
    "inp = torch.arange(0.0, 1.0, 0.02, requires_grad=True).unsqueeze(0)\n",
    "baseline = torch.zeros_like(inp, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7ca42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compeletness_test(model, inp, baseline, attribution, target_class_index, tolerance = 1e-3):\n",
    "    f_inp = model(inp)\n",
    "    f_baseline = model(baseline)\n",
    "    \n",
    "    diff = (f_inp[0][target_class_index] - f_baseline[0][target_class_index]).sum()\n",
    "    attr_sum = attribution.sum()\n",
    "    print(f\"sum of attributions {attr_sum.item()}\")\n",
    "    print(f\"difference of network output at input as baseline {diff.item()}\")\n",
    "    print(f\"approximation error {torch.abs((diff-attr_sum)).item()}\")\n",
    "    \n",
    "    assert torch.abs(attr_sum - diff) <= tolerance, \"failed to pass completness axiom of integrated gradients\"\n",
    "    \n",
    "    print(f\"completness test: passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6afcdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n",
      "sum of attributions 0.004937011425495175\n",
      "difference of network output at input as baseline 0.004918217658996582\n",
      "approximation error 1.879376649859335e-05\n",
      "completness test: passed\n"
     ]
    }
   ],
   "source": [
    "# captum IG method\n",
    "model = Net(num_in, 20, 2)\n",
    "target_class_index = 1\n",
    "\n",
    "# applying integrated gradients on the SoftmaxModel and input data point\n",
    "ig = IntegratedGradients(model)\n",
    "attributions, approximation_error = ig.attribute(inp, target=target_class_index,\n",
    "                                    return_convergence_delta=True)\n",
    "\n",
    "compeletness_test(model, inp, baseline, attributions, target_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f9dd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n",
      "sum of attributions 0.0018184136133641005\n",
      "difference of network output at input as baseline 0.004918217658996582\n",
      "approximation error 0.0030998040456324816\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "failed to pass completness axiom of integrated gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# applying integrated gradients on the SoftmaxModel and input data point\u001b[39;00m\n\u001b[0;32m     12\u001b[0m ig_helmholtz \u001b[38;5;241m=\u001b[39m run_integrated_jacobian_scanvi(model, batches, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mcompeletness_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mig_helmholtz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mcompeletness_test\u001b[1;34m(model, inp, baseline, attribution, target_class_index, tolerance)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifference of network output at input as baseline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapproximation error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mabs((diff\u001b[38;5;241m-\u001b[39mattr_sum))\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mabs(attr_sum \u001b[38;5;241m-\u001b[39m diff) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to pass completness axiom of integrated gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletness test: passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: failed to pass completness axiom of integrated gradients"
     ]
    }
   ],
   "source": [
    "from integrated_gradients_helmholtz import run_integrated_jacobian_scanvi\n",
    "\n",
    "# Helmholtz method\n",
    "model = Net(num_in, 20, 2)\n",
    "num_in = 50\n",
    "inp = torch.arange(0.0, 1.0, 0.02).unsqueeze(0)\n",
    "baseline = torch.zeros_like(inp)\n",
    "\n",
    "batches = [{\"X\":inp, \"batch\":1}]\n",
    "target_class_index = 1\n",
    "# applying integrated gradients on the SoftmaxModel and input data point\n",
    "ig_helmholtz = run_integrated_jacobian_scanvi(model, batches, n_steps=50)\n",
    "compeletness_test(model, inp, baseline, ig_helmholtz[..., target_class_index], target_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa31506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n",
      "sum of attributions 0.004963119514286518\n",
      "difference of network output at input as baseline 0.004918217658996582\n",
      "approximation error 4.4901855289936066e-05\n",
      "completness test: passed\n"
     ]
    }
   ],
   "source": [
    "from integrated_gradients_paper import integrated_gradients, get_gradients_func\n",
    "# paper method\n",
    "num_in = 50\n",
    "model = Net(num_in, 20, 2)\n",
    "inp = torch.arange(0.0, 1.0, 0.02, requires_grad=True).unsqueeze(0)\n",
    "baseline = torch.zeros_like(inp, requires_grad=True)\n",
    "target_class_index = 1\n",
    "# applying integrated gradients on the SoftmaxModel and input data point\n",
    "ig_paper = integrated_gradients(\n",
    "    inp, \n",
    "    target_class_index,\n",
    "    get_gradients_func,\n",
    "    baseline,\n",
    "    model,\n",
    "    steps=50)\n",
    "\n",
    "compeletness_test(model, inp, baseline, ig_paper, target_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bb97204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  9.8100e-05, -2.0390e-04, -1.5306e-04,  3.2287e-04,\n",
       "         -1.8544e-04, -3.9908e-05, -1.4650e-04,  4.9033e-04, -2.1914e-04,\n",
       "          9.2016e-04,  1.0996e-03, -5.3383e-04,  2.6344e-04,  8.8657e-04,\n",
       "         -1.5459e-03, -9.0614e-05, -5.8357e-04, -8.4320e-04, -1.4649e-04,\n",
       "         -5.0780e-05, -1.9186e-03, -1.7589e-03,  1.1854e-03, -7.0733e-04,\n",
       "          7.9240e-04,  1.7168e-03,  2.7485e-03,  3.1179e-04, -1.1015e-03,\n",
       "         -1.7919e-04, -1.8624e-04,  8.9024e-04,  9.2335e-04,  2.5725e-04,\n",
       "          1.6627e-03,  1.2797e-03, -3.3386e-04, -1.5338e-04,  6.7018e-04,\n",
       "         -3.7697e-05,  3.2621e-03, -1.9959e-05, -2.8561e-04, -2.0533e-03,\n",
       "          8.0743e-04,  2.3874e-03, -1.7385e-03, -1.7422e-03, -1.0547e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e488185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  9.6289e-05, -1.9685e-04, -1.5218e-04,  3.1501e-04,\n",
       "         -1.8034e-04, -4.1268e-05, -1.3794e-04,  4.8004e-04, -2.1699e-04,\n",
       "          9.1168e-04,  1.0814e-03, -5.3959e-04,  2.7289e-04,  8.7898e-04,\n",
       "         -1.5232e-03, -9.4753e-05, -5.5742e-04, -8.6005e-04, -1.4349e-04,\n",
       "         -5.4616e-05, -1.9041e-03, -1.7386e-03,  1.1762e-03, -6.7799e-04,\n",
       "          7.8964e-04,  1.6698e-03,  2.6912e-03,  3.6027e-04, -1.0905e-03,\n",
       "         -1.6895e-04, -1.8129e-04,  8.5915e-04,  9.2207e-04,  2.6397e-04,\n",
       "          1.6563e-03,  1.2744e-03, -3.6178e-04, -1.2589e-04,  6.5605e-04,\n",
       "         -6.6314e-06,  3.1829e-03, -2.0143e-05, -2.3274e-04, -2.0229e-03,\n",
       "          7.2358e-04,  2.3485e-03, -1.7478e-03, -1.6721e-03, -1.0231e-03]],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00fe4d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000e+00,  3.4380e-05, -1.0807e-04, -6.4972e-05,  1.5246e-04,\n",
       "         -1.1495e-04, -1.8439e-06, -1.3310e-04,  2.4499e-04, -8.6860e-05,\n",
       "          5.0418e-04,  4.1214e-04, -3.3020e-04,  3.1484e-04,  4.8420e-04,\n",
       "         -6.8562e-04, -1.4832e-05, -4.4818e-05, -1.1595e-04,  4.5136e-05,\n",
       "         -3.9720e-05, -1.0080e-03, -9.8241e-04,  2.1138e-04, -6.1308e-04,\n",
       "          3.4862e-04,  1.3197e-03,  8.1323e-04,  3.7401e-04, -5.5644e-04,\n",
       "          4.1998e-04,  2.6268e-04,  6.1181e-04,  4.2450e-04,  1.3267e-04,\n",
       "          5.8322e-04,  3.0566e-04, -7.8697e-04, -3.9634e-04,  5.6278e-04,\n",
       "         -2.6588e-04,  1.5068e-03, -3.4203e-04,  3.2421e-04, -1.6146e-03,\n",
       "          8.0128e-04,  1.3107e-03, -5.3677e-06, -1.4235e-03, -9.5160e-04]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_helmholtz[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25033776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0226)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(ig_paper - ig_helmholtz[..., 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c77babd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0220, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(attributions - ig_helmholtz[..., 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ae8365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(attributions - ig_paper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr",
   "language": "python",
   "name": "gr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
